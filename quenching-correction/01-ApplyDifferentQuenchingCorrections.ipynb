{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an overview of the workflow used to carry out different quenching corrections on the GNATS glider data. All correction methods are based on [Thomalla et al (2018)](https://aslopubs.onlinelibrary.wiley.com/doi/10.1002/lom3.10234), but with slight adaptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quenching correction options:\n",
    "\n",
    "1. Night: take the mean ($N_m$) or the first and last profiles ($N_{fl}$)\n",
    "2. Euphotic zone: limit quenching depth to be within Zeu ($Zeu_y$) or not ($Zeu_n$) or based on a hard limit ($Zeu_h$)\n",
    "\n",
    "If we do all the combinations of the above we end up with 6 different quenching correction workflows:\n",
    "\n",
    "1. MZy: $N_m\\rightarrow Zeu_y$\n",
    "1. MZn: $N_m\\rightarrow Zeu_n$\n",
    "1. MZh: $N_m\\rightarrow Zeu_h$\n",
    "1. FLZy: $N_{fl}\\rightarrow Zeu_y$\n",
    "1. FLZy: $N_{fl}\\rightarrow Zeu_n$\n",
    "1. FLZh: $N_{fl}\\rightarrow Zeu_h$\n",
    "\n",
    "To do this analysis, we'll make use of the `quenchingFunctions` module which contains a lot of the functions needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation\n",
    "\n",
    "First modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import quenchingFunctions as qf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='Mean of empty slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a list of the glider data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentDir = '../../../data/mission-netcdf/darkCountCorrected/'\n",
    "files = [f for f in os.listdir(parentDir) \n",
    "         if os.path.isfile(os.path.join(parentDir,f))]\n",
    "gFiles = [parentDir + ff for ff in files[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to need the euphotic depth, which is stored in the `secondaryParams.nc` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "secParams = xr.open_dataset('../secondaryParams-v2.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're going to need to iterate through the different correction approaches. In the `quenchingFunctions` module, the euphotic zone conditions are written as different functions, and depending on the night-time interpolation we're going to need different reference arrays. Hence, we are going to need to call different functions, depending on the correction approach. \n",
    "\n",
    "Function Reference Lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnights = {'M' : qf.refArrayMeanNights, 'FL' : qf.refArrayEdgeNights}\n",
    "fzq = {'Zn' : qf.findQuenchingDepthSC, \n",
    "       'Zy' : qf.findQuenchingDepthSCInEZ,\n",
    "       'Zh' : qf.findQuenchingDepthSCupper}\n",
    "directions = ['east', 'west']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction method list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chlcorrmethod = ['MZn', 'MZy', 'MZh',\n",
    "                'FLZn', 'FLZy', 'FLZh', 'nocorr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting the above such that the corrected data are stored in a dataset with three dimensions as described above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying quenching correction methods to all missions\n",
    "\n",
    "Here we'll apply the different quenching corrections to all the glider missions. The output will be two netCDF files (xarray datasets):\n",
    "\n",
    "1. The corrected chlorophyll fluorescence data for all the missions, with all the different correction methods, so we can evaluated the different methods against each other.\n",
    "2. The calculated quenching depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "henry-mission18\n",
      "grampus-mission1\n",
      "grampus-mission2.1\n",
      "grampus-mission2\n",
      "grampus-mission3\n",
      "grampus-mission4\n",
      "grampus-mission5\n",
      "grampus-mission6\n",
      "grampus-mission7\n",
      "grampus-mission8\n",
      "henry-mission1\n",
      "henry-mission2\n",
      "henry-mission3\n",
      "henry-mission4\n",
      "henry-mission5\n",
      "henry-mission6\n",
      "henry-mission7.1\n",
      "henry-mission7\n",
      "henry-mission8\n",
      "henry-mission9\n",
      "henry-mission10\n",
      "henry-mission11\n",
      "henry-mission12\n",
      "henry-mission13\n",
      "henry-mission14\n",
      "henry-mission15\n",
      "henry-mission16\n"
     ]
    }
   ],
   "source": [
    "# preallocating final dataset\n",
    "# need to get the coords from one of the glider mission files\n",
    "# but doesn't matter which, because they all have the same coords\n",
    "gdata = xr.open_dataset(gFiles[0])\n",
    "allCorrectedChl = xr.Dataset(coords = {\n",
    "        \"zbin\": (\"zbin\", gdata.zbin),\n",
    "        \"lonbin\": (\"lonbin\", gdata.lonbin),\n",
    "        \"chlcorrmethod\": (\"chlcorrmethod\", chlcorrmethod)})\n",
    "allQZ = xr.Dataset(coords = {\n",
    "        \"lonbin\": (\"lonbin\", gdata.lonbin),\n",
    "        \"chlcorrmethod\": (\"chlcorrmethod\", chlcorrmethod)})\n",
    "\n",
    "# looping through glider missions\n",
    "for ix,gf in enumerate(gFiles):\n",
    "    # file name manipulations for IDs\n",
    "    gid = re.split('/',gf)[-1][:-3]\n",
    "    g0 = gid[0]\n",
    "    gE = re.search('[0-9]*\\.?[0-9]',gid).group()\n",
    "    \n",
    "    print(gid)\n",
    "    \n",
    "    # import data\n",
    "    gdata = xr.open_dataset(gf)\n",
    "    \n",
    "    # finding nights\n",
    "    nightData = qf.findingNights(gdata)\n",
    "    \n",
    "    # preallocating\n",
    "    missionCorrected = {}\n",
    "    missionQZ = {}\n",
    "    \n",
    "    # quenching correction workflow\n",
    "    for dd in directions:\n",
    "        chlCorrected = []\n",
    "        quenchDepths = []\n",
    "        for nkey, fn in fnights.items(): #for each night condition\n",
    "            for zkey, fz in fzq.items(): #for each quenching & euphotic depth condition\n",
    "\n",
    "                zeu = secParams.sel(mission = gid+'_'+dd).Zeu\n",
    "                refArrays = fn(nightData[dd],gdata,dd,gdata.lonbin)\n",
    "                qdepths = fz(gdata, refArrays, dd, zeu)\n",
    "                quenchDepths +=[qdepths]\n",
    "                correctedChl = qf.correctQuenching(gdata, refArrays, dd, qdepths)              \n",
    "                chlCorrected += [correctedChl.assign_coords(chlcorrmethod=nkey+zkey).expand_dims('chlcorrmethod')]\n",
    "\n",
    "        # storing all the corrected data in a data array temporarily\n",
    "        missionCorrected[dd] = xr.concat(chlCorrected, dim = 'chlcorrmethod')\n",
    "        missionQZ[dd] = xr.DataArray(np.stack(quenchDepths + [np.ones(quenchDepths[0].shape)*np.nan]),coords=[chlcorrmethod,gdata.lonbin],dims=['chlcorrmethod','lonbin'])\n",
    "\n",
    "    # storing the mission data in the final dataset\n",
    "    # this is done in a separate loop to ensure all the chlcorrmethod coordinates\n",
    "    # align correctly when combining into the main dataset\n",
    "    for dd in directions:\n",
    "        rawchl = gdata['chlfl_'+dd].assign_coords(chlcorrmethod = 'nocorr').expand_dims('chlcorrmethod')\n",
    "        allCorrectedChl[g0+gE+'_'+dd] = missionCorrected[dd].combine_first(rawchl)\n",
    "        allQZ[g0+gE+'_'+dd] = missionQZ[dd]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCorrectedChl.to_netcdf('../../../data/quenching-evaluation-netcdf/quenchingCorrectionTests.nc')\n",
    "allQZ.to_netcdf('../../../data/quenching-evaluation-netcdf/quenchingDepths.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
